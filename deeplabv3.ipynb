{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Initial Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0, path=path):\n",
    "        self.path = path\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = np.inf\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, val_loss, model=None):\n",
    "        if self.best_loss - val_loss > self.min_delta:\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "            print(f'Model saved to: {self.path}')\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif self.best_loss - val_loss < self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                print('INFO: Early stopping')\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install pytorch-ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T06:36:46.829134Z",
     "iopub.status.busy": "2023-04-18T06:36:46.828650Z",
     "iopub.status.idle": "2023-04-18T06:36:47.440204Z",
     "shell.execute_reply": "2023-04-18T06:36:47.439243Z",
     "shell.execute_reply.started": "2023-04-18T06:36:46.829092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T06:33:10.663523Z",
     "iopub.status.busy": "2023-04-18T06:33:10.663085Z",
     "iopub.status.idle": "2023-04-18T06:33:10.670456Z",
     "shell.execute_reply": "2023-04-18T06:33:10.669486Z",
     "shell.execute_reply.started": "2023-04-18T06:33:10.663491Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Currently using \"{device}\" device.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T06:33:14.465407Z",
     "iopub.status.busy": "2023-04-18T06:33:14.463779Z",
     "iopub.status.idle": "2023-04-18T06:33:14.483761Z",
     "shell.execute_reply": "2023-04-18T06:33:14.482221Z",
     "shell.execute_reply.started": "2023-04-18T06:33:14.465342Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "batch_size = 4\n",
    "image_size = 256\n",
    "num_classes = 1\n",
    "epochs = 30\n",
    "path = r'seg_model.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crack + Augmented Crack Image 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_crack = '/home/jovyan/aiclops_2023/crack_semantic_segmentation/crack_segmentation_dataset/images'\n",
    "path_crack_aug = '/home/jovyan/aiclops_2023/crack_semantic_segmentation/crack_segmentation_dataset/augmented/images'\n",
    "\n",
    "path_crack_total = '/home/jovyan/aiclops_2023/crack_semantic_segmentation/crack_segmentation_dataset/total_images/'\n",
    "\n",
    "crack_imgs = os.listdir(path_crack)\n",
    "crack_aug_imgs = os.listdir(path_crack_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'crack imgs: {crack_imgs}')\n",
    "print(f'crack augmendted imgs : {crack_aug_imgs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in crack_imgs:\n",
    "    file_path = os.path.join(path_crack, file)\n",
    "    dir_path = os.path.join(path_crack_total, file)\n",
    "    shutil.copy(file_path, dir_path)\n",
    "# print(f\"Copied file from {file_path} to {output_path}\")\n",
    "\n",
    "\n",
    "# 폴더2의 파일을 합친 폴더로 복사\n",
    "for file in crack_aug_imgs:\n",
    "    file_path = os.path.join(path_crack_aug, file)\n",
    "    dir_path = os.path.join(path_crack_total, file)\n",
    "    shutil.copy(file_path, dir_path)\n",
    "    # print(f\"Copied file from {file_path} to {output_path}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-04-18T06:33:19.255355Z",
     "iopub.status.busy": "2023-04-18T06:33:19.254839Z",
     "iopub.status.idle": "2023-04-18T06:33:21.675484Z",
     "shell.execute_reply": "2023-04-18T06:33:21.674396Z",
     "shell.execute_reply.started": "2023-04-18T06:33:19.255319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "path_images = r'/home/jovyan/aiclops_2023/crack_semantic_segmentation/crack_segmentation_dataset/total_images/'\n",
    "path_masks = r'/home/jovyan/aiclops_2023/crack_semantic_segmentation/crack_segmentation_dataset/total_masks/'\n",
    "\n",
    "list_images = glob(path_images + '*.jpg')\n",
    "list_masks = glob(path_masks + '*.jpg')\n",
    "\n",
    "list_sorted_images = sorted([str(p) for p in list_images])\n",
    "list_sorted_masks = sorted([str(p) for p in list_masks])\n",
    "\n",
    "print(f'len(list_sorted_images): {len(list_sorted_images)}')\n",
    "\n",
    "dataframe = pd.DataFrame({'images': list_sorted_images, 'masks': list_sorted_masks})\n",
    "dataframe.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train, Test, Val Dataset 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T06:33:26.907050Z",
     "iopub.status.busy": "2023-04-18T06:33:26.906548Z",
     "iopub.status.idle": "2023-04-18T06:33:26.936197Z",
     "shell.execute_reply": "2023-04-18T06:33:26.934940Z",
     "shell.execute_reply.started": "2023-04-18T06:33:26.907013Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## changed to define test size as % of dataset instead of set value\n",
    "# test_size = 0.30* data size\n",
    "\n",
    "train, test = train_test_split(dataframe, test_size=0.2, shuffle=True, random_state=seed)\n",
    "train, valid = train_test_split(train, test_size=0.25, shuffle=True, random_state=seed)\n",
    "\n",
    "print(f'Train size: {len(train)}, validation size: {len(valid)} and test size: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[19521].squeeze(), train.loc[19521].squeeze().shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T06:33:30.430669Z",
     "iopub.status.busy": "2023-04-18T06:33:30.430147Z",
     "iopub.status.idle": "2023-04-18T06:33:30.442681Z",
     "shell.execute_reply": "2023-04-18T06:33:30.441414Z",
     "shell.execute_reply.started": "2023-04-18T06:33:30.430633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "train_transforms = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((image_size, image_size)), # (256, 256)\n",
    "    T.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T06:33:33.010341Z",
     "iopub.status.busy": "2023-04-18T06:33:33.009834Z",
     "iopub.status.idle": "2023-04-18T06:33:33.037343Z",
     "shell.execute_reply": "2023-04-18T06:33:33.036045Z",
     "shell.execute_reply.started": "2023-04-18T06:33:33.010307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CrackDataset(Dataset):\n",
    "    def __init__(self, dataset, transforms=train_transforms):\n",
    "        self.dataset = dataset.reset_index(drop=True)\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        df_row = self.dataset.loc[ix].squeeze() # df_row: [(images) path_image, (masks) path_mask]\n",
    "        path_image = df_row['images']\n",
    "        path_mask = df_row['masks']\n",
    "                \n",
    "        # image\n",
    "        image = cv2.imread(path_image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image_tensor = self.transforms(image).float()\n",
    "        \n",
    "        # mask\n",
    "        mask = cv2.imread(path_mask)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        mask = cv2.resize(mask, (image_size, image_size))\n",
    "        _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY) # pixel 값이 0~255의 중간값인 127을 기준으로 흑, 백 처리\n",
    "        mask_tensor = torch.as_tensor(mask[None], dtype=torch.float32)\n",
    "\n",
    "        mask_tensor /= 255.\n",
    "        \n",
    "        return image_tensor, mask_tensor\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        images, masks = tuple(zip(*batch))\n",
    "        images = [img[None] for img in images]\n",
    "        masks = [msk[None] for msk in masks]\n",
    "        images, masks = [torch.cat(i).to(device) for i in [images, masks]]\n",
    "        return images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T06:33:37.759324Z",
     "iopub.status.busy": "2023-04-18T06:33:37.758872Z",
     "iopub.status.idle": "2023-04-18T06:33:38.509962Z",
     "shell.execute_reply": "2023-04-18T06:33:38.508985Z",
     "shell.execute_reply.started": "2023-04-18T06:33:37.759291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_train = CrackDataset(train)\n",
    "\n",
    "# image\n",
    "sample_image_tensor = dataset_train[3584][0]\n",
    "plt.subplot(121)\n",
    "plt.imshow(dataset_train[3584][0].cpu().detach().numpy().transpose(1,2,0)) # C x H x W ➡️ H x W x C\n",
    "\n",
    "# mask\n",
    "sample_mask_tensor = dataset_train[3584][1]\n",
    "plt.subplot(122)\n",
    "plt.imshow(dataset_train[3584][1].cpu().detach().numpy().transpose(1,2,0), cmap='gray') # C x H x W ➡️ H x W x C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(pred_mask, true_mask):\n",
    "    # print(f'🔥 true_mask: {true_mask}')\n",
    "     \n",
    "\n",
    "    pred_mask = torch.from_numpy(pred_mask)\n",
    "    pred_mask.squeeze_(dim=2) \n",
    "    pred_mask = torch.clamp(pred_mask, min=0)\n",
    "    # print(f'🔥 pred_mask: {pred_mask}')\n",
    "    pred_mask = pred_mask.numpy()\n",
    "    pred_mask = np.round(255 * pred_mask)\n",
    "    # print(f'🔥 pred_mask: {pred_mask}')\n",
    "\n",
    "    pred_mask = pred_mask.astype(np.uint8)\n",
    "    _, pred_mask = cv2.threshold(pred_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    # print(f'🔥 pred_mask: {pred_mask}')\n",
    "    pred_mask = torch.from_numpy(pred_mask)\n",
    "    true_mask = torch.from_numpy(true_mask)\n",
    "\n",
    "    # print(f'⭐ pred_mask: {pred_mask}')\n",
    "    # print(f'⭐ true_mask: {true_mask}')\n",
    "    pred_mask = (pred_mask >= 255).bool()\n",
    "    true_mask = (true_mask >= 255).bool()\n",
    "    print(f'🔥 pred_mask: {torch.sum(pred_mask)}')\n",
    "\n",
    "    intersection = torch.logical_and(pred_mask, true_mask)\n",
    "    union = torch.logical_or(pred_mask, true_mask)\n",
    "    print(torch.sum(intersection))\n",
    "    print(torch.sum(union))\n",
    "    iou = torch.sum(intersection) / torch.sum(union)\n",
    "    # # print(f'✅ pred_mask: {pred_mask}, \\n true_mask: {true_mask}')\n",
    "\n",
    "    # intersection = torch.logical_and(pred_mask, true_mask)\n",
    "    # union = torch.logical_or(pred_mask, true_mask)\n",
    "    # iou = torch.sum(intersection) / torch.sum(union)\n",
    "    \n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dice(pred_mask, true_mask):    \n",
    "    \n",
    "    pred_mask = torch.from_numpy(pred_mask)\n",
    "    pred_mask.squeeze_(dim=2) \n",
    "    pred_mask = pred_mask.numpy()\n",
    "    pred_mask = np.round( 255 * pred_mask)\n",
    "    pred_mask = pred_mask.astype(np.uint8)\n",
    "    _, pred_mask = cv2.threshold(pred_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    pred_mask = torch.from_numpy(pred_mask)\n",
    "    true_mask = torch.from_numpy(true_mask)\n",
    "    \n",
    "    pred_mask = (pred_mask >= 255).float()\n",
    "    true_mask = (true_mask >= 255).float()\n",
    "\n",
    "    \n",
    "    \n",
    "    intersection = torch.sum(pred_mask * true_mask)\n",
    "    union = torch.sum(pred_mask) + torch.sum(true_mask)\n",
    "\n",
    "    dice = 2 * intersection / (union + 1e-8)\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T06:33:43.885413Z",
     "iopub.status.busy": "2023-04-18T06:33:43.884887Z",
     "iopub.status.idle": "2023-04-18T06:33:43.905815Z",
     "shell.execute_reply": "2023-04-18T06:33:43.904711Z",
     "shell.execute_reply.started": "2023-04-18T06:33:43.885374Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_test_image(model, dataset):\n",
    "    idx = np.random.randint(len(dataset))\n",
    "    dataset = dataset.reset_index(drop=True)\n",
    "    df_row = dataset.loc[idx].squeeze()\n",
    "    \n",
    "    # image\n",
    "    image = cv2.imread(df_row['images'])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_tensor = train_transforms(image).unsqueeze(0).to(device)\n",
    "    #print(f'image_tensor.dtype: {image_tensor.dtype}')\n",
    "    #print(f'image.shape: {image_tensor.shape}')\n",
    "    #print('--------------')\n",
    "\n",
    "# [Original Version]\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "    # Mask \n",
    "    mask = cv2.imread(df_row['masks'])\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    mask = cv2.resize(mask, (image_size, image_size))\n",
    "    _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "    predicted_mask = model(image_tensor)\n",
    "    predicted_mask = predicted_mask['out'][0].cpu().detach().numpy().transpose(1,2,0)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# [New Version]\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "    # mask\n",
    "    # mask = cv2.imread(df_row['masks'])  \n",
    "    # mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    # mask = cv2.resize(mask, (image_size, image_size))\n",
    "    # _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    # mask = torch.from_numpy(mask)\n",
    "    #print(f'mask.dtype: {mask.dtype}')\n",
    "    #print(f'mask.shape: {mask.shape}')\n",
    "    #print('--------------')\n",
    "\n",
    "    \n",
    "    # ⭐ Inference\n",
    "    # model.eval()\n",
    "    # predicted_mask = model(image_tensor)\n",
    "    # predicted_mask = predicted_mask['out'][0].cpu().detach().numpy().transpose(1,2,0)\n",
    "\n",
    "    # predicted_mask = torch.from_numpy(predicted_mask) \n",
    "    # predicted_mask.squeeze_(dim=2) \n",
    "   \n",
    "    # predicted_mask = predicted_mask.numpy()\n",
    "    # predicted_mask = np.round( 255 * predicted_mask)\n",
    "    # predicted_mask = predicted_mask.astype(np.uint8)\n",
    "\n",
    "    # _, predicted_mask = cv2.threshold(predicted_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    # predicted_mask = torch.from_numpy(predicted_mask)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "\n",
    "    #print(predicted_mask)\n",
    "    #print(f'predicted_mask.dtype: {predicted_mask.dtype}')    \n",
    "    #print(f'predicted_mask.shape: {predicted_mask.shape}')   \n",
    "        \n",
    "  \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(131)\n",
    "    plt.title('Original image')\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    plt.title('Original mask')\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    \n",
    "    plt.subplot(133)\n",
    "    plt.title('Predicted mask')\n",
    "    plt.imshow(predicted_mask, cmap='gray')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.pause(0.001)\n",
    "    \n",
    "    print(f'image shape: {image.shape}, label mask shape: {mask.shape}, predicted mask shape: {predicted_mask.shape}')\n",
    "    \n",
    "  \n",
    "    IoU = calculate_iou(predicted_mask, mask)\n",
    "    dice = calculate_dice(predicted_mask, mask)\n",
    "\n",
    "    print(f'✅ IoU: {IoU}')\n",
    "    print(f'🎲 dice: {dice}')\n",
    "\n",
    "    return IoU, dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T06:33:52.852430Z",
     "iopub.status.busy": "2023-04-18T06:33:52.851960Z",
     "iopub.status.idle": "2023-04-18T06:33:52.869331Z",
     "shell.execute_reply": "2023-04-18T06:33:52.868101Z",
     "shell.execute_reply.started": "2023-04-18T06:33:52.852395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = CrackDataset(train)\n",
    "valid_dataset = CrackDataset(valid)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=train_dataset.collate_fn, drop_last=True) # batch_size = 4\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=valid_dataset.collate_fn, drop_last=True) # batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T06:36:56.040099Z",
     "iopub.status.busy": "2023-04-18T06:36:56.039693Z",
     "iopub.status.idle": "2023-04-18T06:37:18.684020Z",
     "shell.execute_reply": "2023-04-18T06:37:18.680786Z",
     "shell.execute_reply.started": "2023-04-18T06:36:56.040065Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "\n",
    "def get_model(output_channels=1, unfreeze=True):\n",
    "    model = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=True, progress=False)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = unfreeze # True\n",
    "    \n",
    "    model.classifier = DeepLabHead(2048, output_channels) # output_channels = 1\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "model = get_model()  # set output_channels = 3 if we work with colored masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-28T23:03:23.561767Z",
     "iopub.status.busy": "2022-11-28T23:03:23.560762Z",
     "iopub.status.idle": "2022-11-28T23:03:23.57794Z",
     "shell.execute_reply": "2022-11-28T23:03:23.576851Z",
     "shell.execute_reply.started": "2022-11-28T23:03:23.561729Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # if unfreeze=True -> 1e-4, 1e-5, so not to ruin good init w\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, min_lr=1e-6, factor=0.1)\n",
    "early = EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-28T23:03:23.580308Z",
     "iopub.status.busy": "2022-11-28T23:03:23.579999Z",
     "iopub.status.idle": "2022-11-28T23:03:23.588291Z",
     "shell.execute_reply": "2022-11-28T23:03:23.587218Z",
     "shell.execute_reply.started": "2022-11-28T23:03:23.580256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_batch(batch, model, criterion, optimizer):\n",
    "    images, masks = batch\n",
    "    optimizer.zero_grad()\n",
    "    predicted_masks = model(images)['out']\n",
    "    # print(f'✅ predicted_masks.shape =', predicted_masks.shape)\n",
    "    # print(f'✅ predicted_masks=', predicted_masks)\n",
    "    # print(f'🔥 mask = {masks}' )\n",
    "    \n",
    "    loss = criterion(predicted_masks, masks)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "\n",
    "def validate_one_batch(batch, model, criterion):\n",
    "    images, masks = batch\n",
    "    prediction_masks = model(images)['out']\n",
    "    loss = criterion(prediction_masks, masks) # 4 x 1 x 256 x 256 (batch x C x H x W)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, valid_losses = [], []\n",
    "ious, dices = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T00:36:54.839853Z",
     "iopub.status.busy": "2022-11-29T00:36:54.834619Z",
     "iopub.status.idle": "2022-11-29T00:36:55.027318Z",
     "shell.execute_reply": "2022-11-29T00:36:55.025431Z",
     "shell.execute_reply.started": "2022-11-29T00:36:54.839668Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    epoch_train_losses, epoch_valid_losses = [], []\n",
    "    \n",
    "    # 🏋️ Training\n",
    "    model.train()\n",
    "    for _, batch in enumerate(tqdm(train_dataloader, leave=False)):\n",
    "        batch_train_loss = train_one_batch(batch, model, criterion, optimizer)\n",
    "        epoch_train_losses.append(batch_train_loss)\n",
    "\n",
    "    epoch_train_loss = np.array(epoch_train_losses).mean()\n",
    "    train_losses.append(epoch_train_loss)\n",
    "\n",
    "    print(f'Train loss: {epoch_train_loss:.4f}.')\n",
    "    \n",
    "    # ⭐ Inference\n",
    "    model.eval()\n",
    "    for i, batch in enumerate(tqdm(valid_dataloader, leave=False)):\n",
    "        batch_valid_loss = validate_one_batch(batch, model, criterion)\n",
    "        epoch_valid_losses.append(batch_valid_loss)\n",
    "        \n",
    "    epoch_valid_loss = np.array(epoch_valid_losses).mean()\n",
    "    valid_losses.append(epoch_valid_loss)\n",
    "    print(f'Valid loss: {epoch_valid_loss:.4f}.')\n",
    "    print('-'*50)\n",
    "\n",
    "    # Score & Early Stopping\n",
    "    IoU, dice = validate_test_image(model, test)\n",
    "    ious.append(IoU), dices.append(dice)\n",
    "    \n",
    "    print(f'✅ IoU: {IoU}')\n",
    "    print(f'🎲 dice: {dice}')\n",
    "\n",
    "    print(f'1️⃣ IoU List: {ious}')\n",
    "    print(f'2️⃣ dice List: {dices}')\n",
    "    scheduler.step(epoch_valid_loss)\n",
    "    early(epoch_valid_loss, model=model)\n",
    "    if early.early_stop:\n",
    "        print(f'Validation loss did not improve for {early.patience} epochs. Training stopped.')\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr></hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
